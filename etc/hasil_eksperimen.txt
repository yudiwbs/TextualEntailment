Hasil Ekperimen
===============

Dataset: RTE3  (data training/develop)

=======================================
Eksprimen April 2015
Akurasi model, 10 cross validation

- mulai lagi dari awal, buat file langkah2_eksperimen
- mulai dari hasil terbaik LSA => lama eksperimennya!
- satu fitur, skor LSA, terbaik Naive Bayes: 62.375
- tambah fitur tf_idf langsung: 66.5
  - kalau hanya tf_idf_langsung  (tanpa skor LSA) 64.375
-

=======================================
Ekps1:
Nama file: similar-langsung.arff
Skenario: RTE.t dan RTE.h dibobot tf-idf, diukur kedekatan dengan cosine similarity
Fitur: kedekatan (cosine) tfidf t dan h
Teknik: naive bayes
Hasil:  64.35

Eksp2:
Skenario: menggunakan LSA
Library yang digunakan: TML-LSA
Fitur: kedekatan+skor LSA
teknik: naive bayes
Hasil:  66.66

Eksp3a:
Skenario: menggunakan Wordnet
Library yang digunakan:
-https://code.google.com/p/ws4j/
Fitur:
kedekatan,skorLSA,kedekatan berdasarkan wordnet (WuPalmer)

Kedekatan wordnet dihitung dari total skor kedekatan dibagi dengan jumlah kata t x jumlah kata h
Akurasi: 66.00  --> gagal, malah turun


Eks 3b
Sama dengan 3a, tapi dengan membuang stopwords, ada efek?
Hasil: 65.85 (gagal)

Eks 3c. Menggunakan isi paper (ekspansi vektor berd wordnet) Yuhua Li
Hasil: 65.75 (gagal)

Eks 4a: menggunakan Lemmatization
Tools stanford (prosesLemma)
cosine_tfidf_lemma + LSA_lemma (spt skenario 2, tapi menggunakan text lemma)
Hasil:65.6  (gagal)

Eks4b:
Spt 4a, tapi ditambahkan juga cosinetfidf+lSA yg non lemma
Hasil: 66.00 (gagal)

Eks4c:
menggunakan simwordnet (versi yw), tapi hanya diterapkan pada t-h lemma
cosinetfidf+LSA tetap menggunakan t dan h standard.
Hasil:65.62 (gagal

Eks5





====
query:

select
id,similar_tfidf_langsung,skorLSA,isEntail
from rte3






